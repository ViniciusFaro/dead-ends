{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gooVb7ciueSC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "from PIL import Image\n",
        "from random import randint\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "from math import sqrt\n",
        "import matplotlib.pyplot as plt\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import cv2\n",
        "import networkx as nx"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qglAeeMFuwqI",
        "outputId": "bf5db0ef-c838-4206-b8fe-27d54e8bed34"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJCSmCtGuyHk",
        "outputId": "6e61c021-4dcf-4a3c-f0b0-3ac73e93b03b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_test_folder = r'/content/drive/MyDrive/data/deadends/test/input'\n",
        "label_test_folder = r'/content/drive/MyDrive/data/deadends/test/label'\n",
        "\n",
        "binary_test_folder = r'/content/drive/MyDrive/data/deadends/test/binary'"
      ],
      "metadata": {
        "id": "Z-PwmfC1u4BX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# obtaining metadata\n",
        "\n",
        "INF = 999.0\n",
        "\n",
        "def calculate_tortuosity(mask: np.ndarray, start: tuple, end: tuple):\n",
        "    \"\"\"\n",
        "    Calculate tortuosity using Dijkstra algorithm.\n",
        "\n",
        "    Args:\n",
        "        mask (numpy ndarray): binary mask.\n",
        "        start (tuple of ints): (x, y) start point coordinates.\n",
        "        end (tuple of ints): (x, y) end point coordinates.\n",
        "\n",
        "    Returns:\n",
        "        float: the tortuosity between the two `start` and `end` points\n",
        "        None: if there is no conection between them\n",
        "    \"\"\"\n",
        "    G = nx.grid_2d_graph(*mask.shape)\n",
        "    for (x, y) in list(G.nodes):\n",
        "        if mask[x, y] == 0:\n",
        "            G.remove_node((x, y))\n",
        "\n",
        "    for edge in G.edges:\n",
        "        G.edges[edge]['weight'] = 1\n",
        "\n",
        "    try:\n",
        "        path = nx.shortest_path(G, source=start, target=end, weight='weight')\n",
        "        length_real = nx.shortest_path_length(G, source=start, target=end, weight='weight') # djikstra algorithm\n",
        "    except nx.NetworkXNoPath:\n",
        "        return None\n",
        "    length_direct = np.linalg.norm(np.array(start) - np.array(end))\n",
        "    tau = length_real / length_direct\n",
        "    return tau\n",
        "\n",
        "# set of all possible coordenates for chossing points\n",
        "\n",
        "# this work for all images:\n",
        "def list_points(img_array: np.ndarray):\n",
        "    \"\"\"\n",
        "    Iterate over a numpy 2D array to check for valid points (points where value equals 1.0)\n",
        "\n",
        "    Args:\n",
        "        img_array (numpy ndarray): Binary image where the iteration will be performed\n",
        "    \"\"\"\n",
        "    valid_points = []\n",
        "    for i in range(img_array.shape[0]):\n",
        "        for j in range(img_array.shape[1]):\n",
        "            if img_array[i, j] == 1:\n",
        "                valid_points.append((i, j))\n",
        "    return valid_points\n",
        "\n",
        "def iterative_tortuosity(mask: np.ndarray, n: int, valids: list):\n",
        "\n",
        "    if len(valids) == 0 or len(valids) == 1:\n",
        "        return 1 # study if 1 is really the best choice\n",
        "\n",
        "    final_tortuosity = 0.0\n",
        "    denominator = n\n",
        "    for i in range(0, n):\n",
        "        start = valids[randint(0, len(valids)-1)]\n",
        "        end = valids[randint(0, len(valids)- 1)]\n",
        "        while (start[0] == end[0] and start[1] == end[1]):\n",
        "            end = valids[randint(0, len(valids)- 1)]\n",
        "        tortuosity = calculate_tortuosity(mask, start, end)\n",
        "        if tortuosity == None:\n",
        "            denominator -= 1\n",
        "            continue\n",
        "        else:\n",
        "            final_tortuosity += tortuosity\n",
        "    if denominator <= 0:\n",
        "        return 1\n",
        "    return (final_tortuosity/denominator).item()\n",
        "\n",
        "input_aug_folder = r'/content/data/train/input'\n",
        "label_aug_folder = r'/content/data/train/label'\n",
        "\n",
        "def calculate_metadata(folder_path: str):\n",
        "    metadata = []\n",
        "    num_imgs = len(os.listdir(folder_path))\n",
        "    for _ in range(0, num_imgs):\n",
        "        metadata.append(torch.zeros(3))\n",
        "\n",
        "    percent20 = False\n",
        "    percent40 = False\n",
        "    percent60 = False\n",
        "    percent80 = False\n",
        "    i = 0\n",
        "    for filename in sorted(os.listdir(folder_path), key=lambda x: int(x.split(\".\")[0])):\n",
        "        img = np.array(Image.open(os.path.join(folder_path, filename)), dtype=np.float32) / 255\n",
        "        img = (img >= 0.5).astype(np.float32)\n",
        "\n",
        "        # calculate porosity\n",
        "        phi = (np.sum(img == 1)/ (200 * 200)).item()\n",
        "        metadata[i][0] = phi\n",
        "\n",
        "        # calculate tortuosity\n",
        "        pores = list_points(img)\n",
        "        tau = iterative_tortuosity(img, 20, pores)\n",
        "        metadata[i][1] = tau\n",
        "\n",
        "        # pseudo-permeability kozeny-carman equation (without the constant)\n",
        "        k = (phi**3)/((1 - phi)**2 * tau**2)\n",
        "\n",
        "        metadata[i][2] = k\n",
        "\n",
        "\n",
        "        i += 1\n",
        "        print(i)\n",
        "        if (i / num_imgs > 0.8 and percent80 == False):\n",
        "            print(\"80%\")\n",
        "            percent80 = True\n",
        "            continue\n",
        "        if (i / num_imgs > 0.6 and percent60 == False):\n",
        "            print(\"60%\")\n",
        "            percent60 = True\n",
        "            continue\n",
        "        if (i / num_imgs > 0.4 and percent40 == False):\n",
        "            print(\"40%\")\n",
        "            percent40 = True\n",
        "            continue\n",
        "        if (i / num_imgs > 0.2 and percent20 == False):\n",
        "            print(\"20%\")\n",
        "            percent20 = True\n",
        "    print(\"100%\")\n",
        "    return metadata\n",
        "\n",
        "print(\"-----test  metadata-----\")\n",
        "test_metadata = calculate_metadata(binary_test_folder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gJjiPuzvAsf",
        "outputId": "0754cc61-12c3-4a93-e885-8ab491be2b7a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----test  metadata-----\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "20%\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "40%\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "60%\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "80%\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "100%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset class\n",
        "\n",
        "class DeadEnds(Dataset):\n",
        "    def __init__(self, img_dir, mask_dir, vector_data, img_transform=None, mask_transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            img_dir (str): Directory with the input images.\n",
        "            mask_dir (str): Directory with the corresponding segmentation masks.\n",
        "            vector_data (list or array): A list (or array) of vectors (each with 3 elements) for each image.\n",
        "                                         Make sure len(vector_data) == number of images in img_dir.\n",
        "            img_transform (callable, optional): Optional transform to be applied on the input image.\n",
        "            mask_transform (callable, optional): Optional transform to be applied on the mask.\n",
        "        \"\"\"\n",
        "        self.img_dir = img_dir\n",
        "        self.mask_dir = mask_dir\n",
        "        self.vector_data = vector_data\n",
        "        self.img_transform = img_transform\n",
        "        self.mask_transform = mask_transform\n",
        "\n",
        "        self.images = sorted(os.listdir(self.img_dir), key=lambda x: int(x.split(\".\")[0]))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.images[idx]\n",
        "        img_path = os.path.join(self.img_dir, img_name)\n",
        "        mask_path = os.path.join(self.mask_dir, img_name)\n",
        "\n",
        "        image = Image.open(img_path)\n",
        "        mask = Image.open(mask_path).convert(\"L\")\n",
        "\n",
        "        if self.img_transform:\n",
        "            image = self.img_transform(image)\n",
        "        if self.mask_transform:\n",
        "            mask = self.mask_transform(mask)\n",
        "\n",
        "        vec_item = self.vector_data[idx]\n",
        "        if isinstance(vec_item, torch.Tensor):\n",
        "            vector = vec_item.clone().detach()\n",
        "        else:\n",
        "            vector = torch.tensor(vec_item, dtype=torch.float32)\n",
        "\n",
        "        return image, vector.unsqueeze(0).unsqueeze(0), mask"
      ],
      "metadata": {
        "id": "RSmQMpJfu7NH"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask_transform = transforms.Compose([\n",
        "    transforms.Resize((160, 160)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "test_dataset = DeadEnds(binary_test_folder, label_test_folder, test_metadata, mask_transform, mask_transform)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False, pin_memory=True)\n",
        "\n",
        "len(test_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIJFZTxqu_dg",
        "outputId": "806304ce-071d-4304-9d22-d277a898c56d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SelfAttention(nn.Module):\n",
        "    def __init__(self, semantic):\n",
        "        super(SelfAttention, self).__init__()\n",
        "\n",
        "        # overlapping embedding (query, key, value)\n",
        "        self.query = nn.Conv2d(in_channels=semantic, out_channels=semantic, kernel_size=3, stride=1, padding=1)\n",
        "        self.key = nn.Conv2d(in_channels=semantic, out_channels=semantic, kernel_size=3, stride=1, padding=1)\n",
        "        self.value = nn.Conv2d(in_channels=semantic, out_channels=semantic, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "        # normalization constant\n",
        "        self.normalizer = sqrt(semantic * 4)\n",
        "\n",
        "        self.flatten = nn.Flatten(2, 3)  # flatten for the attention calculation\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, h, w = x.size()\n",
        "\n",
        "        # Apply query, key, and value convolutions\n",
        "        q = self.flatten(self.query(x))\n",
        "        k = self.flatten(self.key(x))\n",
        "        v = self.flatten(self.value(x))\n",
        "\n",
        "        # Compute scaled dot-product attention\n",
        "        scaled = torch.bmm(q, k.permute(0, 2, 1)) / self.normalizer\n",
        "\n",
        "        # Attention output reshaped back into original size\n",
        "        return torch.bmm(F.softmax(scaled, dim=-1), v).reshape(b, c, h, w)"
      ],
      "metadata": {
        "id": "pn_ci0CkvaDy"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DCA(nn.Module):\n",
        "    def __init__(self, ic, oc):\n",
        "        super(DCA, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=ic, out_channels=oc, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(num_features=oc)\n",
        "        self.relu1 = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(in_channels=oc, out_channels=oc, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(oc)\n",
        "\n",
        "        self.attention = SelfAttention(semantic=oc)\n",
        "\n",
        "        self.relu2 = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu1(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "\n",
        "        x = self.attention(x)\n",
        "        x = self.relu2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "wGYGPXNWvbdn"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ExpansionNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ExpansionNet, self).__init__()\n",
        "\n",
        "        # DCA-Head\n",
        "        self.dcah = DCA(ic=1, oc=16)\n",
        "\n",
        "        # Expansion-Head\n",
        "        self.bn = nn.BatchNorm2d(1)\n",
        "        self.expansion_transpose = nn.ConvTranspose2d(\n",
        "                                    in_channels=1,\n",
        "                                    out_channels=16,\n",
        "                                    kernel_size=(160, 40),\n",
        "                                    stride=(1, 60),\n",
        "                                    padding=(0, 0),\n",
        "                                    output_padding=(0, 0)\n",
        "                                )\n",
        "        self.expansion_attention = SelfAttention(16)\n",
        "\n",
        "        # encoder\n",
        "        self.dca1 = DCA(ic=64//2, oc=128//2)\n",
        "        self.dca2 = DCA(ic=128//2, oc=256//2)\n",
        "        self.dca3 = DCA(ic=256//2, oc=512//2)\n",
        "        self.dca4 = DCA(ic=512//2, oc=1024//2)\n",
        "        self.dca5 = DCA(ic=1024//2, oc=2048//2)\n",
        "\n",
        "        # bottleneck\n",
        "        self.bottom_conv = nn.Conv2d(in_channels=2048//2,\n",
        "                                     out_channels=2048//2,\n",
        "                                     kernel_size=3,\n",
        "                                     stride=1,\n",
        "                                     padding=1)\n",
        "        self.bottom_norm = nn.BatchNorm2d(num_features=2048//2)\n",
        "        self.unity_conv = nn.Conv2d(in_channels=2048//2,\n",
        "                                    out_channels=2048//2,\n",
        "                                    kernel_size=1,\n",
        "                                    stride=1,\n",
        "                                    padding=0)\n",
        "\n",
        "        # decoder\n",
        "        self.dca6 = DCA(ic = 4096//2, oc=2048//2)\n",
        "\n",
        "        self.transpose1 = nn.ConvTranspose2d(in_channels=2048//2,\n",
        "                                             out_channels=1024//2,\n",
        "                                             kernel_size=2,\n",
        "                                             stride=2,\n",
        "                                             padding=0,\n",
        "                                             output_padding=0)\n",
        "\n",
        "        self.dca7 = DCA(ic=2048//2, oc=1024//2)\n",
        "\n",
        "        self.transpose2 = nn.ConvTranspose2d(in_channels=1024//2,\n",
        "                                             out_channels=512//2,\n",
        "                                             kernel_size=2,\n",
        "                                             stride=2,\n",
        "                                             padding=0,\n",
        "                                             output_padding=0)\n",
        "\n",
        "        self.dca8 = DCA(ic=1024//2, oc=512//2)\n",
        "\n",
        "        self.transpose3 = nn.ConvTranspose2d(in_channels=512//2,\n",
        "                                             out_channels=256//2,\n",
        "                                             kernel_size=2,\n",
        "                                             stride=2, padding=0,\n",
        "                                             output_padding=0)\n",
        "\n",
        "        self.dca9 = DCA(ic=512//2, oc=256//2)\n",
        "\n",
        "        self.transpose4 = nn.ConvTranspose2d(in_channels=256//2,\n",
        "                                             out_channels=128//2,\n",
        "                                             kernel_size=2,\n",
        "                                             stride=2,\n",
        "                                             padding=0,\n",
        "                                             output_padding=0)\n",
        "\n",
        "        self.dca10 = DCA(ic=256//2, oc=128//2)\n",
        "\n",
        "        self.final_conv = nn.Conv2d(in_channels=128//2,\n",
        "                                    out_channels=1,\n",
        "                                    kernel_size=3,\n",
        "                                    stride=1,\n",
        "                                    padding=1)\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=False)\n",
        "        self.pool = nn.MaxPool2d((2, 2))\n",
        "\n",
        "    def forward(self, img, vec):\n",
        "        img = self.dcah(img)\n",
        "        expanded = self.relu(self.expansion_attention(self.expansion_transpose(self.bn(vec))))\n",
        "        x = torch.cat((img, expanded), dim=1)\n",
        "\n",
        "        # encoder\n",
        "        enc1 = self.dca1(x)\n",
        "        enc2 = self.pool(self.dca2(enc1))\n",
        "        enc3 = self.pool(self.dca3(enc2))\n",
        "        enc4 = self.pool(self.dca4(enc3))\n",
        "        enc5 = self.pool(self.dca5(enc4))\n",
        "\n",
        "        # bottleneck\n",
        "        bottom1 = self.relu(self.bottom_norm(self.bottom_conv(enc5)))\n",
        "        bottom2 = self.relu(self.bottom_norm(self.unity_conv(bottom1)))\n",
        "\n",
        "        # decoder\n",
        "        dec1 = self.dca6(torch.cat((enc5, bottom2), dim=1))\n",
        "        dec2 = self.dca7(torch.cat((enc4, self.transpose1(dec1)), dim=1))\n",
        "        dec3 = self.dca8(torch.cat((enc3, self.transpose2(dec2)), dim=1))\n",
        "        dec4 = self.dca9(torch.cat((enc2, self.transpose3(dec3)), dim=1))\n",
        "        dec5 = self.dca10(torch.cat((enc1, self.transpose4(dec4)), dim=1))\n",
        "\n",
        "        return self.final_conv(dec5)"
      ],
      "metadata": {
        "id": "znKoGU8fvcxX"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define evaluation metrics\n",
        "\n",
        "def calculate_iou(pred: torch.Tensor, target: torch.Tensor, threshold: float = 0.5) -> float:\n",
        "    \"\"\"\n",
        "    Calculate Intersection over Union (IoU) for two 1-channel tensors.\n",
        "\n",
        "    Args:\n",
        "        pred (torch.Tensor): Predicted binary mask (1-channel, shape HxW or BxHxW).\n",
        "        target (torch.Tensor): Ground truth binary mask (1-channel, same shape as pred).\n",
        "        threshold (float): Threshold to binarize predicted mask (default 0.5).\n",
        "\n",
        "    Returns:\n",
        "        float: IoU value.\n",
        "    \"\"\"\n",
        "    # Ensure the inputs are binary\n",
        "    pred = (pred >= threshold).float()  # Binarize predictions\n",
        "    target = target.float()             # Ensure ground truth is float\n",
        "\n",
        "    # Compute intersection and union\n",
        "    intersection = torch.sum(pred * target)\n",
        "    union = torch.sum(pred + target) - intersection\n",
        "\n",
        "    # Avoid division by zero\n",
        "    if union == 0:\n",
        "        return 1.0 if intersection == 0 else 0.0\n",
        "\n",
        "    # Compute IoU\n",
        "    iou = intersection / union\n",
        "    return iou.item()\n",
        "\n",
        "def pixel_accuracy(pred_mask, true_mask):\n",
        "    \"\"\"\n",
        "    Compute Pixel Accuracy between two segmentation masks.\n",
        "\n",
        "    Args:\n",
        "        pred_mask (np.array): Predicted segmentation mask.\n",
        "        true_mask (np.array): Ground truth segmentation mask.\n",
        "\n",
        "    Returns:\n",
        "        float: Pixel accuracy score.\n",
        "    \"\"\"\n",
        "    correct_pixels = np.equal(pred_mask, true_mask).sum()\n",
        "    total_pixels = true_mask.size\n",
        "    return correct_pixels / total_pixels"
      ],
      "metadata": {
        "id": "jbE8bBMCvfAI"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = r'/content/drive/MyDrive/data/models/deadend-model3.pth'\n",
        "\n",
        "model = ExpansionNet().to(device)\n",
        "\n",
        "model.load_state_dict(torch.load(model_path, weights_only=True))\n",
        "\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-fegQ5YviBR",
        "outputId": "196e172b-8e90-4c31-ded6-57d9f048f565"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ExpansionNet(\n",
              "  (dcah): DCA(\n",
              "    (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu1): ReLU(inplace=True)\n",
              "    (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (attention): SelfAttention(\n",
              "      (query): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (key): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (value): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (flatten): Flatten(start_dim=2, end_dim=3)\n",
              "    )\n",
              "    (relu2): ReLU(inplace=True)\n",
              "  )\n",
              "  (bn): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (expansion_transpose): ConvTranspose2d(1, 16, kernel_size=(160, 40), stride=(1, 60))\n",
              "  (expansion_attention): SelfAttention(\n",
              "    (query): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (key): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (value): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (flatten): Flatten(start_dim=2, end_dim=3)\n",
              "  )\n",
              "  (dca1): DCA(\n",
              "    (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu1): ReLU(inplace=True)\n",
              "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (attention): SelfAttention(\n",
              "      (query): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (key): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (value): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (flatten): Flatten(start_dim=2, end_dim=3)\n",
              "    )\n",
              "    (relu2): ReLU(inplace=True)\n",
              "  )\n",
              "  (dca2): DCA(\n",
              "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu1): ReLU(inplace=True)\n",
              "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (attention): SelfAttention(\n",
              "      (query): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (key): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (value): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (flatten): Flatten(start_dim=2, end_dim=3)\n",
              "    )\n",
              "    (relu2): ReLU(inplace=True)\n",
              "  )\n",
              "  (dca3): DCA(\n",
              "    (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu1): ReLU(inplace=True)\n",
              "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (attention): SelfAttention(\n",
              "      (query): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (key): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (value): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (flatten): Flatten(start_dim=2, end_dim=3)\n",
              "    )\n",
              "    (relu2): ReLU(inplace=True)\n",
              "  )\n",
              "  (dca4): DCA(\n",
              "    (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu1): ReLU(inplace=True)\n",
              "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (attention): SelfAttention(\n",
              "      (query): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (key): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (value): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (flatten): Flatten(start_dim=2, end_dim=3)\n",
              "    )\n",
              "    (relu2): ReLU(inplace=True)\n",
              "  )\n",
              "  (dca5): DCA(\n",
              "    (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu1): ReLU(inplace=True)\n",
              "    (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (attention): SelfAttention(\n",
              "      (query): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (key): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (value): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (flatten): Flatten(start_dim=2, end_dim=3)\n",
              "    )\n",
              "    (relu2): ReLU(inplace=True)\n",
              "  )\n",
              "  (bottom_conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bottom_norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (unity_conv): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "  (dca6): DCA(\n",
              "    (conv1): Conv2d(2048, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu1): ReLU(inplace=True)\n",
              "    (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (attention): SelfAttention(\n",
              "      (query): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (key): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (value): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (flatten): Flatten(start_dim=2, end_dim=3)\n",
              "    )\n",
              "    (relu2): ReLU(inplace=True)\n",
              "  )\n",
              "  (transpose1): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
              "  (dca7): DCA(\n",
              "    (conv1): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu1): ReLU(inplace=True)\n",
              "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (attention): SelfAttention(\n",
              "      (query): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (key): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (value): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (flatten): Flatten(start_dim=2, end_dim=3)\n",
              "    )\n",
              "    (relu2): ReLU(inplace=True)\n",
              "  )\n",
              "  (transpose2): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
              "  (dca8): DCA(\n",
              "    (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu1): ReLU(inplace=True)\n",
              "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (attention): SelfAttention(\n",
              "      (query): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (key): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (value): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (flatten): Flatten(start_dim=2, end_dim=3)\n",
              "    )\n",
              "    (relu2): ReLU(inplace=True)\n",
              "  )\n",
              "  (transpose3): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
              "  (dca9): DCA(\n",
              "    (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu1): ReLU(inplace=True)\n",
              "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (attention): SelfAttention(\n",
              "      (query): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (key): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (value): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (flatten): Flatten(start_dim=2, end_dim=3)\n",
              "    )\n",
              "    (relu2): ReLU(inplace=True)\n",
              "  )\n",
              "  (transpose4): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
              "  (dca10): DCA(\n",
              "    (conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu1): ReLU(inplace=True)\n",
              "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (attention): SelfAttention(\n",
              "      (query): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (key): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (value): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (flatten): Flatten(start_dim=2, end_dim=3)\n",
              "    )\n",
              "    (relu2): ReLU(inplace=True)\n",
              "  )\n",
              "  (final_conv): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (relu): ReLU()\n",
              "  (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "save_path = r'/content/drive/MyDrive/data/deadends/test/results3'\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "for idx, (s, v, m) in enumerate(test_dataset):\n",
        "    model.eval()\n",
        "    s = s.to(device)\n",
        "    v = v.to(device)\n",
        "    pred = model(s.unsqueeze(0), v.unsqueeze(0)).detach().cpu()\n",
        "\n",
        "    sample = nn.Sigmoid()(s).detach().cpu().squeeze().numpy()\n",
        "    mask = nn.Sigmoid()(m).detach().cpu().squeeze().numpy()\n",
        "    pred = (nn.Sigmoid()(pred) >= 0.7).float().detach().cpu().squeeze().numpy()\n",
        "\n",
        "    sample_img = (sample * 255).astype(np.uint8)\n",
        "    mask_img = (mask * 255).astype(np.uint8)\n",
        "    pred_img = (pred * 255).astype(np.uint8)\n",
        "\n",
        "    Image.fromarray(sample_img).save(os.path.join(save_path, f'{idx}_input_image{idx}.png'))\n",
        "    Image.fromarray(mask_img).save(os.path.join(save_path, f'{idx}_original_segmentation.png'))\n",
        "    Image.fromarray(pred_img).save(os.path.join(save_path, f'{idx}_predicted.png'))\n",
        "\n",
        "print(f'Imagens salvas em {save_path}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMeFEpF6wYox",
        "outputId": "dab72006-74a1-40c2-ea98-a24af0e8a29a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imagens salvas em /content/drive/MyDrive/data/deadends/test/results3\n"
          ]
        }
      ]
    }
  ]
}